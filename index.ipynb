{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data harmoinsation in imaging - the problem\n",
    "## Author: David M Cash\n",
    "## Principal Research Fellow, Dementia Research Centre, UCL Queen Square Institute of Neurology\n",
    "This notebook was made as part of the **Health and Bioscience IDEAS** training programme, funded by the [UKRI Innovation Scholars](https://www.ukri.org/opportunity/innovation-scholars-data-science-training-in-health-bioscience/) Data Science Training in Health and Bioscience. Please visit [our website](https://healthbioscienceideas.github.io/) for more information.\n",
    "\n",
    "This notebook will give a brief example of how differences can arise when acquiring data using multiple scanners in a study. For more background on this, please see the [accompanying documenation](https://healthbioscienceideas.github.io/demon-imaging-harmonisation/). \n",
    "\n",
    "To illustrate this probelm, let's take a scenario where we expect the least amount of change. We will look at two scans from a cogntively normal individual, one scanned on Scanner A, and another scanned on scanner B. Both scanners are have a magnetic field strength of 3 Tesla; however, they are two different models. We will register the two scans together and determine what, if any, differences are present between the two.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "To start with, we will import a few basic packages and setup the notebook to have interactive content (the matplotlib widget *magic* command in Jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "For this demonstration, I used [Datalad](https://www.datalad.org/) to setup the data repository. Datalad is built upon git and git-annex, and it provides version control for data management, data sharing and reproducible science. For this lesson, it offers us a convenient way of grabbing the data that we need. These comamands import datalad so that we can use it to clone the repository into our virtual machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datalad.api as dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we \"clone\" the repository to a local destination. No big files are downloaded yet, just the metadata so this computer know what data exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Fetching updates for Dataset(/tmp/sample) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".: demons-data(?) [git]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'action': 'enable-sibling',\n",
       "  'path': '/tmp/sample',\n",
       "  'type': 'sibling',\n",
       "  'name': 'demons-data',\n",
       "  'refds': '/tmp/sample',\n",
       "  'status': 'ok'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_source='https://github.com/HealthBioscienceIDEAS/demon-imaging-data.git'\n",
    "sample=dl.clone(dl_source,path='/tmp/sample',description='Cloned sample dataset for import')\n",
    "sample.update(merge=True)\n",
    "sample.siblings(action='enable',name='demons-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get our first and second image from the same individual using the datalad get command. Big data is not downloaded automaticaly when cloning a repository with datalad. It is only downloaded as/when it is needed, saving valuable space, especially when working with large repositories. The initial download will take a few seconds, so please be patient. When it is running, there will be an * between the square brackets, and when complete, it will have a number next to it and a little output.bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/sample/baseline_t1.nii.gz\n"
     ]
    }
   ],
   "source": [
    "bl_img=sample.get('./baseline_t1.nii.gz')\n",
    "print(bl_img[0]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/sample/followup_t1.nii.gz\n"
     ]
    }
   ],
   "source": [
    "fu_img=sample.get('./followup_t1.nii.gz')\n",
    "print(fu_img[0]['path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrasubject registration\n",
    "The python package [nipype](https://nipype.readthedocs.io/en/latest/index.html) provides an effective means in Python to run your image processing workflows, taking \"building blocks\" of individual commands, allowing you to piece together bits of various software packages (FSL, SPM, FreeSurfer, AFNI, MRtrix, etc) into complete pipelines. We are just going to use it to perform a simple registration between our baseline and followup image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces import niftyreg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets up the node that will run rigid registration using  [NiftyReg](https://github.com/KCL-BMEIS/niftyreg), a lightweight easy to use registration package. We set the inputs and outputs up, and it will generate the command line, which you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reg_aladin -aff /Users/davecash/src/demon-imaging-harmonisation/results/followup_to_baseline_aff.txt -flo /tmp/sample/followup_t1.nii.gz -omp 1 -ref /tmp/sample/baseline_t1.nii.gz -res /Users/davecash/src/demon-imaging-harmonisation/results/followup_t1_resampled.nii.gz -voff'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path=os.path.join(os.getcwd(),'results')\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "followup_aff=os.path.join(out_path,'followup_to_baseline_aff.txt')\n",
    "followup_res=os.path.join(out_path,'followup_t1_resampled.nii.gz')\n",
    "node = niftyreg.RegAladin(verbosity_off_flag=True)\n",
    "node.inputs.ref_file = bl_img[0]['path']\n",
    "node.inputs.flo_file = fu_img[0]['path']\n",
    "node.inputs.aff_file = followup_aff\n",
    "node.inputs.res_file = followup_res\n",
    "node.cmdline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are happy with the command setup, then we run the code. This might take a little while, as no output will appear below until the registration is completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210913-13:29:26,170 nipype.interface INFO:\n",
      "\t stdout 2021-09-13T13:29:26.169810:[NiftyReg WARNING] NiftyReg has not been compiled with OpenMP, the '-omp' flag is ignored\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nipype.interfaces.base.support.InterfaceResult at 0x7fe63502c4d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/davecash/src/demon-imaging-harmonisation/results/baseline_t1.nii.gz'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_nii=os.path.join(out_path,'baseline_t1.nii.gz')\n",
    "shutil.copyfile(bl_img[0]['path'],baseline_nii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has now generated the affine transformation between the two images and a resampled followup image. You can now see these and the baseline imagein the results directory of the notebook (should be on the left hand side). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the registration\n",
    "\n",
    "After the registration. the corresponding anatomy should be aligned in the baseline image and the registered followup image. The best way to check the registration is to download the images from the results directory and then open them up in your favourite image viewer, so that you can look at both images with a linked cursor, or by toggling back and forth between the imags, so that you can visually see the differences. You can also look at them through this notebook below using a lightweight 3D slice viewer called [nanslice](https://github.com/spinicist/nanslice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nanslice.jupyter as ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at the baseline image. Scroll around using the sliders for the slice location. You can also change the brightness and contrast by modifying the clim argument in the line below.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c14df582da48738eee5137a0a04502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182bec318ebc44bf910d728c9979ea77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FloatSlider(value=0.000164031982421875, description='X:', max=113.85000610351562…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base=ns.Layer(baseline_nii,clim=(30,350),label=\"Baseline\")\n",
    "ns.three_plane(base,cbar=True,interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the repeat - The original clim arguments should produce similar greyscales for both. Make sure the slice sliders have the same location for both viewers.  \n",
    "**What differences do you notice?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998779a6523a4fe389492020f32a70b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980bfa6b14b042109cd19b9a03d4836b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FloatSlider(value=0.000164031982421875, description='X:', max=113.85000610351562…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "repeat=ns.Layer(followup_res,clim=(20,220),label=\"Followup\")\n",
    "ns.three_plane(repeat,cbar=True,interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, changing scanners can also result in subtle geometric distortions between scans, which can result in differences in volume that are not physiological or pathological in nature. The animated GIF below which toggles between the baseline and followup scan shows not just the changes in intensity and contrast between the two scans, but changes in shape as well.  These three effects are some of the main reasons for why data harmonisation between sites are needed. \n",
    "![DistortionExample](registration.gif \"registration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (GUI)",
   "language": "python",
   "name": "python3w"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
